{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cde8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9945bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1     2     3     4    5     6     7     8     9     10    11  \\\n",
       "0    1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04   \n",
       "1    1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05   \n",
       "2    1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03   \n",
       "3    1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86   \n",
       "4    1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04   \n",
       "5    1  14.20  1.76  2.45  15.2  112  3.27  3.39  0.34  1.97  6.75  1.05   \n",
       "6    1  14.39  1.87  2.45  14.6   96  2.50  2.52  0.30  1.98  5.25  1.02   \n",
       "7    1  14.06  2.15  2.61  17.6  121  2.60  2.51  0.31  1.25  5.05  1.06   \n",
       "8    1  14.83  1.64  2.17  14.0   97  2.80  2.98  0.29  1.98  5.20  1.08   \n",
       "9    1  13.86  1.35  2.27  16.0   98  2.98  3.15  0.22  1.85  7.22  1.01   \n",
       "10   1  14.10  2.16  2.30  18.0  105  2.95  3.32  0.22  2.38  5.75  1.25   \n",
       "11   1  14.12  1.48  2.32  16.8   95  2.20  2.43  0.26  1.57  5.00  1.17   \n",
       "12   1  13.75  1.73  2.41  16.0   89  2.60  2.76  0.29  1.81  5.60  1.15   \n",
       "13   1  14.75  1.73  2.39  11.4   91  3.10  3.69  0.43  2.81  5.40  1.25   \n",
       "14   1  14.38  1.87  2.38  12.0  102  3.30  3.64  0.29  2.96  7.50  1.20   \n",
       "15   1  13.63  1.81  2.70  17.2  112  2.85  2.91  0.30  1.46  7.30  1.28   \n",
       "16   1  14.30  1.92  2.72  20.0  120  2.80  3.14  0.33  1.97  6.20  1.07   \n",
       "17   1  13.83  1.57  2.62  20.0  115  2.95  3.40  0.40  1.72  6.60  1.13   \n",
       "18   1  14.19  1.59  2.48  16.5  108  3.30  3.93  0.32  1.86  8.70  1.23   \n",
       "19   1  13.64  3.10  2.56  15.2  116  2.70  3.03  0.17  1.66  5.10  0.96   \n",
       "\n",
       "      12    13  \n",
       "0   3.92  1065  \n",
       "1   3.40  1050  \n",
       "2   3.17  1185  \n",
       "3   3.45  1480  \n",
       "4   2.93   735  \n",
       "5   2.85  1450  \n",
       "6   3.58  1290  \n",
       "7   3.58  1295  \n",
       "8   2.85  1045  \n",
       "9   3.55  1045  \n",
       "10  3.17  1510  \n",
       "11  2.82  1280  \n",
       "12  2.90  1320  \n",
       "13  2.73  1150  \n",
       "14  3.00  1547  \n",
       "15  2.88  1310  \n",
       "16  2.65  1280  \n",
       "17  2.57  1130  \n",
       "18  2.82  1680  \n",
       "19  3.36   845  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine.data.orig', header=None)  \n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f580a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f2ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142 entries, 91 to 37\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       142 non-null    int64  \n",
      " 1   1       142 non-null    float64\n",
      " 2   2       142 non-null    float64\n",
      " 3   3       142 non-null    float64\n",
      " 4   4       142 non-null    float64\n",
      " 5   5       142 non-null    int64  \n",
      " 6   6       142 non-null    float64\n",
      " 7   7       142 non-null    float64\n",
      " 8   8       142 non-null    float64\n",
      " 9   9       142 non-null    float64\n",
      " 10  10      142 non-null    float64\n",
      " 11  11      142 non-null    float64\n",
      " 12  12      142 non-null    float64\n",
      " 13  13      142 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 16.6 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=1)\n",
    "Xtrn = train_set.iloc[:, 1:]\n",
    "Ytrn = train_set.iloc[:, 0]\n",
    "Xtst = test_set.iloc[:, 1:]\n",
    "Ytst = test_set.iloc[:, 0]\n",
    "\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31691cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
      "91   12.00  1.51  2.42  22.0   86  1.45  1.25  0.50  1.63  3.60  1.05  2.65   \n",
      "81   12.72  1.81  2.20  18.8   86  2.20  2.53  0.26  1.77  3.90  1.16  3.14   \n",
      "114  12.08  1.39  2.50  22.5   84  2.56  2.29  0.43  1.04  2.90  0.93  3.19   \n",
      "48   14.10  2.02  2.40  18.8  103  2.75  2.92  0.32  2.38  6.20  1.07  2.75   \n",
      "54   13.74  1.67  2.25  16.4  118  2.60  2.90  0.21  1.62  5.85  0.92  3.20   \n",
      "..     ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "133  12.70  3.55  2.36  21.5  106  1.70  1.20  0.17  0.84  5.00  0.78  1.29   \n",
      "137  12.53  5.51  2.64  25.0   96  1.79  0.60  0.63  1.10  5.00  0.82  1.69   \n",
      "72   13.49  1.66  2.24  24.0   87  1.88  1.84  0.27  1.03  3.74  0.98  2.78   \n",
      "140  12.93  2.81  2.70  21.0   96  1.54  0.50  0.53  0.75  4.60  0.77  2.31   \n",
      "37   13.05  1.65  2.55  18.0   98  2.45  2.43  0.29  1.44  4.25  1.12  2.51   \n",
      "\n",
      "       13  \n",
      "91    450  \n",
      "81    714  \n",
      "114   385  \n",
      "48   1060  \n",
      "54   1060  \n",
      "..    ...  \n",
      "133   600  \n",
      "137   515  \n",
      "72    472  \n",
      "140   600  \n",
      "37   1105  \n",
      "\n",
      "[142 rows x 13 columns]\n",
      "        1     2     3     4    5     6     7     8     9      10    11    12  \\\n",
      "161  13.69  3.26  2.54  20.0  107  1.83  0.56  0.50  0.80   5.88  0.96  1.82   \n",
      "117  12.42  1.61  2.19  22.5  108  2.00  2.09  0.34  1.61   2.06  1.06  2.96   \n",
      "19   13.64  3.10  2.56  15.2  116  2.70  3.03  0.17  1.66   5.10  0.96  3.36   \n",
      "69   12.21  1.19  1.75  16.8  151  1.85  1.28  0.14  2.50   2.85  1.28  3.07   \n",
      "53   13.77  1.90  2.68  17.1  115  3.00  2.79  0.39  1.68   6.30  1.13  2.93   \n",
      "138  13.49  3.59  2.19  19.5   88  1.62  0.48  0.58  0.88   5.70  0.81  1.82   \n",
      "112  11.76  2.68  2.92  20.0  103  1.75  2.03  0.60  1.05   3.80  1.23  2.50   \n",
      "14   14.38  1.87  2.38  12.0  102  3.30  3.64  0.29  2.96   7.50  1.20  3.00   \n",
      "160  12.36  3.83  2.38  21.0   88  2.30  0.92  0.50  1.04   7.65  0.56  1.58   \n",
      "107  12.72  1.75  2.28  22.5   84  1.38  1.76  0.48  1.63   3.30  0.88  2.42   \n",
      "11   14.12  1.48  2.32  16.8   95  2.20  2.43  0.26  1.57   5.00  1.17  2.82   \n",
      "4    13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04  2.93   \n",
      "108  12.22  1.29  1.94  19.0   92  2.36  2.04  0.39  2.08   2.70  0.86  3.02   \n",
      "42   13.88  1.89  2.59  15.0  101  3.25  3.56  0.17  1.70   5.43  0.88  3.56   \n",
      "84   11.84  0.89  2.58  18.0   94  2.20  2.21  0.22  2.35   3.05  0.79  3.08   \n",
      "113  11.41  0.74  2.50  21.0   88  2.48  2.01  0.42  1.44   3.08  1.10  2.31   \n",
      "152  13.11  1.90  2.75  25.5  116  2.20  1.28  0.26  1.56   7.10  0.61  1.33   \n",
      "35   13.48  1.81  2.41  20.5  100  2.70  2.98  0.26  1.86   5.10  1.04  3.47   \n",
      "105  12.42  2.55  2.27  22.0   90  1.68  1.84  0.66  1.42   2.70  0.86  3.30   \n",
      "31   13.58  1.66  2.36  19.1  106  2.86  3.19  0.22  1.95   6.90  1.09  2.88   \n",
      "51   13.83  1.65  2.60  17.2   94  2.45  2.99  0.22  2.29   5.60  1.24  3.37   \n",
      "126  12.43  1.53  2.29  21.5   86  2.74  3.15  0.39  1.77   3.94  0.69  2.84   \n",
      "130  12.86  1.35  2.32  18.0  122  1.51  1.25  0.21  0.94   4.10  0.76  1.29   \n",
      "73   12.99  1.67  2.60  30.0  139  3.30  2.89  0.21  1.96   3.35  1.31  3.50   \n",
      "40   13.56  1.71  2.31  16.2  117  3.15  3.29  0.34  2.34   6.13  0.95  3.38   \n",
      "162  12.85  3.27  2.58  22.0  106  1.65  0.60  0.60  0.96   5.58  0.87  2.11   \n",
      "47   13.90  1.68  2.12  16.0  101  3.10  3.39  0.21  2.14   6.10  0.91  3.33   \n",
      "29   14.02  1.68  2.21  16.0   96  2.65  2.33  0.26  1.98   4.70  1.04  3.59   \n",
      "16   14.30  1.92  2.72  20.0  120  2.80  3.14  0.33  1.97   6.20  1.07  2.65   \n",
      "147  12.87  4.61  2.48  21.5   86  1.70  0.65  0.47  0.86   7.65  0.54  1.86   \n",
      "97   12.29  1.41  1.98  16.0   85  2.55  2.50  0.29  1.77   2.90  1.23  2.74   \n",
      "159  13.48  1.67  2.64  22.5   89  2.60  1.10  0.52  2.29  11.75  0.57  1.78   \n",
      "151  12.79  2.67  2.48  22.0  112  1.48  1.36  0.24  1.26  10.80  0.48  1.47   \n",
      "5    14.20  1.76  2.45  15.2  112  3.27  3.39  0.34  1.97   6.75  1.05  2.85   \n",
      "120  11.45  2.40  2.42  20.0   96  2.90  2.79  0.32  1.83   3.25  0.80  3.39   \n",
      "94   11.62  1.99  2.28  18.0   98  3.02  2.26  0.17  1.35   3.25  1.16  2.96   \n",
      "\n",
      "       13  \n",
      "161   680  \n",
      "117   345  \n",
      "19    845  \n",
      "69    718  \n",
      "53   1375  \n",
      "138   580  \n",
      "112   607  \n",
      "14   1547  \n",
      "160   520  \n",
      "107   488  \n",
      "11   1280  \n",
      "4     735  \n",
      "108   312  \n",
      "42   1095  \n",
      "84    520  \n",
      "113   434  \n",
      "152   425  \n",
      "35    920  \n",
      "105   315  \n",
      "31   1515  \n",
      "51   1265  \n",
      "126   352  \n",
      "130   630  \n",
      "73    985  \n",
      "40    795  \n",
      "162   570  \n",
      "47    985  \n",
      "29   1035  \n",
      "16   1280  \n",
      "147   625  \n",
      "97    428  \n",
      "159   620  \n",
      "151   480  \n",
      "5    1450  \n",
      "120   625  \n",
      "94    345  \n"
     ]
    }
   ],
   "source": [
    "print(Xtrn)\n",
    "print(Xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e3409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91     2\n",
      "81     2\n",
      "114    2\n",
      "48     1\n",
      "54     1\n",
      "      ..\n",
      "133    3\n",
      "137    3\n",
      "72     2\n",
      "140    3\n",
      "37     1\n",
      "Name: 0, Length: 142, dtype: int64\n",
      "161    3\n",
      "117    2\n",
      "19     1\n",
      "69     2\n",
      "53     1\n",
      "138    3\n",
      "112    2\n",
      "14     1\n",
      "160    3\n",
      "107    2\n",
      "11     1\n",
      "4      1\n",
      "108    2\n",
      "42     1\n",
      "84     2\n",
      "113    2\n",
      "152    3\n",
      "35     1\n",
      "105    2\n",
      "31     1\n",
      "51     1\n",
      "126    2\n",
      "130    3\n",
      "73     2\n",
      "40     1\n",
      "162    3\n",
      "47     1\n",
      "29     1\n",
      "16     1\n",
      "147    3\n",
      "97     2\n",
      "159    3\n",
      "151    3\n",
      "5      1\n",
      "120    2\n",
      "94     2\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Ytrn)\n",
    "print(Ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a7fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors                      # import the KNN classifier\n",
    "clf = neighbors.KNeighborsClassifier(1) \n",
    "# clf.fit(X, Y) # train classifer with wholedata\n",
    "# clf.score(X, Y) #training accuracy on X\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9486333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e12f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295774647887324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 2\n",
    "from sklearn import tree                         # import the decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f8b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611111111111112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e234a111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\envs\\ProjectTKU\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9647887323943662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 3\n",
    "from sklearn import linear_model                 # import package\n",
    "clf = linear_model.LogisticRegression(C=10**10)\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316dc17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde69913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 4\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # import package\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ac4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a42f3f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 5\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b8776e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939e2977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084507042253521"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 6\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier()\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d305cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f095f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577465"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 7\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb9ecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02fe8228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 8\n",
    "from sklearn import svm\n",
    "#clf = svm.SVC(kernel='linear',C=1**1)\n",
    "clf = svm.SVC(kernel='linear',C=10**10)\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8733d92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a21afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6619718309859155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier 9\n",
    "from sklearn import svm\n",
    "#clf = svm.SVC(kernel='linear',C=1**1)\n",
    "clf = svm.SVC(kernel='poly',C=0.1, degree=2)\n",
    "\n",
    "clf.fit(Xtrn, Ytrn) # train classifer with train_data\n",
    "clf.score(Xtrn, Ytrn) #training accuracy on Xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8063f064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6388888888888888"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtst, Ytst) #testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b733e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
